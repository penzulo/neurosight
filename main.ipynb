{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMG_SIZE: tuple[int, int] = (512, 512)\n",
    "BATCH_SIZE: int = 8\n",
    "EPOCHS: int = 30\n",
    "BASE_DIR: str = \"./brain_scans\" # Root folder containing glioma, meningioma, and pituitary_tumor folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Image Loading\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    validation_split=0.2 # 20% data for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2452 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_directory(\n",
    "    BASE_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\" # Set for training data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 612 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = datagen.flow_from_directory(\n",
    "    BASE_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\" # Set for validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained ResNet50 Model (without the top layers)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the convolutional base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new custom layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(3, activation=\"softmax\")(x) # 3 classes for glioma, meningioma, pituitary tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "307/307 [==============================] - 3183s 10s/step - loss: 7.4566 - accuracy: 0.4719 - val_loss: 1.0950 - val_accuracy: 0.4657 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "307/307 [==============================] - 3150s 10s/step - loss: 0.8787 - accuracy: 0.6252 - val_loss: 4.6196 - val_accuracy: 0.3039 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "307/307 [==============================] - 3164s 10s/step - loss: 0.7320 - accuracy: 0.6896 - val_loss: 1.3554 - val_accuracy: 0.4837 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "307/307 [==============================] - 3147s 10s/step - loss: 0.6494 - accuracy: 0.7227 - val_loss: 1.0271 - val_accuracy: 0.5196 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "307/307 [==============================] - 3137s 10s/step - loss: 0.7237 - accuracy: 0.7076 - val_loss: 1.6666 - val_accuracy: 0.5131 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "307/307 [==============================] - 3122s 10s/step - loss: 0.6215 - accuracy: 0.7488 - val_loss: 0.8382 - val_accuracy: 0.6830 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "307/307 [==============================] - 3147s 10s/step - loss: 0.6040 - accuracy: 0.7529 - val_loss: 55.8687 - val_accuracy: 0.4706 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "307/307 [==============================] - 3124s 10s/step - loss: 0.5678 - accuracy: 0.7647 - val_loss: 3.7032 - val_accuracy: 0.5131 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "307/307 [==============================] - 3152s 10s/step - loss: 0.5081 - accuracy: 0.7961 - val_loss: 0.5220 - val_accuracy: 0.7794 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "307/307 [==============================] - 3126s 10s/step - loss: 0.4888 - accuracy: 0.8006 - val_loss: 1.9618 - val_accuracy: 0.4314 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "307/307 [==============================] - 3115s 10s/step - loss: 0.5155 - accuracy: 0.7940 - val_loss: 1.4173 - val_accuracy: 0.5261 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "307/307 [==============================] - 3103s 10s/step - loss: 0.5323 - accuracy: 0.7940 - val_loss: 3.1469 - val_accuracy: 0.5572 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "307/307 [==============================] - 3104s 10s/step - loss: 0.3696 - accuracy: 0.8471 - val_loss: 0.5835 - val_accuracy: 0.7418 - lr: 2.0000e-04\n",
      "Epoch 14/30\n",
      "307/307 [==============================] - 3128s 10s/step - loss: 0.3326 - accuracy: 0.8593 - val_loss: 0.4399 - val_accuracy: 0.8529 - lr: 2.0000e-04\n",
      "Epoch 15/30\n",
      "307/307 [==============================] - 3122s 10s/step - loss: 0.3247 - accuracy: 0.8801 - val_loss: 0.7266 - val_accuracy: 0.6993 - lr: 2.0000e-04\n",
      "Epoch 16/30\n",
      "307/307 [==============================] - 3137s 10s/step - loss: 0.3138 - accuracy: 0.8691 - val_loss: 0.8038 - val_accuracy: 0.7190 - lr: 2.0000e-04\n",
      "Epoch 17/30\n",
      "307/307 [==============================] - 3134s 10s/step - loss: 0.2786 - accuracy: 0.8891 - val_loss: 0.8598 - val_accuracy: 0.7304 - lr: 2.0000e-04\n",
      "Epoch 18/30\n",
      "307/307 [==============================] - 3132s 10s/step - loss: 0.2438 - accuracy: 0.9033 - val_loss: 0.4385 - val_accuracy: 0.8333 - lr: 4.0000e-05\n",
      "Epoch 19/30\n",
      "307/307 [==============================] - 3139s 10s/step - loss: 0.2376 - accuracy: 0.9062 - val_loss: 0.2960 - val_accuracy: 0.8725 - lr: 4.0000e-05\n",
      "Epoch 20/30\n",
      "307/307 [==============================] - 3146s 10s/step - loss: 0.2232 - accuracy: 0.9103 - val_loss: 0.3134 - val_accuracy: 0.8546 - lr: 4.0000e-05\n",
      "Epoch 21/30\n",
      "307/307 [==============================] - 3171s 10s/step - loss: 0.2247 - accuracy: 0.9123 - val_loss: 0.4542 - val_accuracy: 0.8415 - lr: 4.0000e-05\n",
      "Epoch 22/30\n",
      "307/307 [==============================] - 3131s 10s/step - loss: 0.2231 - accuracy: 0.9123 - val_loss: 0.4730 - val_accuracy: 0.8317 - lr: 4.0000e-05\n",
      "Epoch 23/30\n",
      "307/307 [==============================] - 3141s 10s/step - loss: 0.2083 - accuracy: 0.9221 - val_loss: 0.2945 - val_accuracy: 0.8791 - lr: 8.0000e-06\n",
      "Epoch 24/30\n",
      "307/307 [==============================] - 3130s 10s/step - loss: 0.1932 - accuracy: 0.9241 - val_loss: 0.3105 - val_accuracy: 0.8840 - lr: 8.0000e-06\n",
      "Epoch 25/30\n",
      "307/307 [==============================] - 3131s 10s/step - loss: 0.2014 - accuracy: 0.9241 - val_loss: 0.2799 - val_accuracy: 0.8938 - lr: 8.0000e-06\n",
      "Epoch 26/30\n",
      "307/307 [==============================] - 3150s 10s/step - loss: 0.2031 - accuracy: 0.9241 - val_loss: 0.2945 - val_accuracy: 0.8938 - lr: 8.0000e-06\n",
      "Epoch 27/30\n",
      "307/307 [==============================] - 3166s 10s/step - loss: 0.2042 - accuracy: 0.9229 - val_loss: 0.3089 - val_accuracy: 0.8824 - lr: 8.0000e-06\n",
      "Epoch 28/30\n",
      "307/307 [==============================] - 3134s 10s/step - loss: 0.1986 - accuracy: 0.9229 - val_loss: 0.2803 - val_accuracy: 0.8889 - lr: 8.0000e-06\n",
      "Epoch 29/30\n",
      "307/307 [==============================] - 3130s 10s/step - loss: 0.2003 - accuracy: 0.9266 - val_loss: 0.2764 - val_accuracy: 0.8938 - lr: 1.6000e-06\n",
      "Epoch 30/30\n",
      "307/307 [==============================] - 3135s 10s/step - loss: 0.2052 - accuracy: 0.9188 - val_loss: 0.2738 - val_accuracy: 0.9036 - lr: 1.6000e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"brain_tumor_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 175s 2s/step - loss: 0.2882 - accuracy: 0.8840\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 88.40%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
